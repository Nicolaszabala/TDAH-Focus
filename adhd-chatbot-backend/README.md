# ğŸ¤– ADHD Chatbot Backend API

Backend API para el asistente conversacional de la aplicaciÃ³n TDAH Focus App. Utiliza modelos LLM opensource de Hugging Face para generar respuestas naturales y contextualizadas.

---

## ğŸ“‹ Tabla de Contenidos

- [CaracterÃ­sticas](#caracterÃ­sticas)
- [Arquitectura](#arquitectura)
- [InstalaciÃ³n](#instalaciÃ³n)
- [ConfiguraciÃ³n](#configuraciÃ³n)
- [Uso](#uso)
- [Deployment](#deployment)
- [API Reference](#api-reference)
- [Troubleshooting](#troubleshooting)

---

## âœ¨ CaracterÃ­sticas

- **LLM Real**: Usa Flan-T5-large (780M parÃ¡metros) de Google via Hugging Face
- **100% Gratuito**: Funciona en tier gratuito de Hugging Face + Render.com
- **CachÃ© Inteligente**: Reduce llamadas API y mejora latencia
- **Rate Limiting**: ProtecciÃ³n contra abuso
- **Fallback Robusto**: Si LLM falla, usa respuestas basadas en patrones
- **Privacidad**: Solo recibe metadata, NO contenido de tareas
- **Respuestas Contextuales**: Considera estado del usuario (tareas, sesiones Pomodoro)

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Native   â”‚
â”‚   ADHD App      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTPS POST /api/chat
         â”‚ { message, context }
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Express API    â”‚
â”‚  Node.js        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Rate Limiter  â”‚
â”‚ â€¢ Cache Layer   â”‚
â”‚ â€¢ Prompt Builderâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Hugging Face Inference API
         â”‚ Bearer token auth
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Hugging Face    â”‚
â”‚ Flan-T5-large   â”‚
â”‚ (Serverless)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes

- **server.js**: Servidor Express principal
- **routes/chat.js**: Endpoints de la API de chat
- **services/llmService.js**: IntegraciÃ³n con Hugging Face
- **services/promptBuilder.js**: ConstrucciÃ³n de prompts contextualizados
- **utils/cache.js**: Sistema de cachÃ© en memoria
- **middleware/rateLimit.js**: LimitaciÃ³n de tasa de requests

---

## ğŸš€ InstalaciÃ³n

### Requisitos Previos

- Node.js 16+ ([Descargar](https://nodejs.org/))
- npm o yarn
- Cuenta en Hugging Face ([Registrarse gratis](https://huggingface.co/join))

### Pasos de InstalaciÃ³n

#### 1. Clonar el Proyecto

```bash
cd adhd-chatbot-backend
```

#### 2. Instalar Dependencias

```bash
npm install
```

Esto instalarÃ¡:
- `express`: Framework web
- `cors`: Manejo de CORS
- `dotenv`: Variables de entorno
- `axios`: Cliente HTTP
- `express-rate-limit`: Rate limiting

#### 3. Configurar Variables de Entorno

**IMPORTANTE PARA EVALUADORES:** El archivo `.env.example` ya incluye un token de Hugging Face funcional.

Crear archivo `.env` desde el template:

```bash
cp .env.example .env
```

Edita el archivo `.env` y reemplaza `TU_TOKEN_AQUI` con el token de Hugging Face proporcionado en el README principal del repositorio.

El archivo `.env` debe quedar asÃ­:

```env
PORT=3000
NODE_ENV=production
HUGGING_FACE_API_KEY=<token_proporcionado_en_readme>
MAX_REQUESTS_PER_MINUTE=20
CACHE_TTL_SECONDS=3600
ALLOWED_ORIGINS=http://localhost:19006,exp://192.168.1.0:19000
```

**Ver el README principal del repositorio para obtener el token funcional de demostraciÃ³n.**

#### 4. (Opcional) Obtener tu Propio API Key de Hugging Face

Si deseas usar tu propio token:

1. Ir a https://huggingface.co/
2. Registrarse (gratis)
3. Ir a Settings â†’ Access Tokens
4. Click en "New token"
5. Nombre: `adhd-chatbot-api`
6. Role: `read`
7. Copiar el token (empieza con `hf_`)
8. Reemplazar el valor en `.env` como `HUGGING_FACE_API_KEY`

#### 5. Iniciar Servidor en Desarrollo

```bash
npm run dev
```

DeberÃ­as ver:

```
==================================================
ğŸš€ ADHD Chatbot API Server
==================================================
Environment: development
Port: 3000
Health check: http://localhost:3000/health
API endpoint: http://localhost:3000/api/chat
==================================================
```

---

## âš™ï¸ ConfiguraciÃ³n

### Variables de Entorno

| Variable | DescripciÃ³n | Default | Requerido |
|----------|-------------|---------|-----------|
| `PORT` | Puerto del servidor | 3000 | No |
| `NODE_ENV` | Entorno (development/production) | development | No |
| `HUGGING_FACE_API_KEY` | API key de Hugging Face | - | **SÃ­** |
| `MAX_REQUESTS_PER_MINUTE` | LÃ­mite de requests por minuto/IP | 20 | No |
| `CACHE_TTL_SECONDS` | Tiempo de vida del cachÃ© (segundos) | 3600 | No |
| `ALLOWED_ORIGINS` | OrÃ­genes permitidos (CORS) | localhost | No |

### ConfiguraciÃ³n del Modelo LLM

Por defecto usa `google/flan-t5-large`. Para cambiar el modelo, editar `services/llmService.js`:

```javascript
const HF_API_URL = 'https://api-inference.huggingface.co/models/google/flan-t5-large';
```

Modelos alternativos:
- `google/flan-t5-base` (mÃ¡s rÃ¡pido, menos preciso)
- `google/flan-t5-xl` (mÃ¡s lento, mÃ¡s preciso - requiere tier pago)

---

## ğŸ“– Uso

### Testing Local con cURL

#### Test de Health Check

```bash
curl http://localhost:3000/health
```

Respuesta:
```json
{
  "status": "ok",
  "timestamp": "2025-11-15T12:00:00.000Z",
  "uptime": 123.45,
  "environment": "development"
}
```

#### Test de Chat

```bash
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "No sÃ© por dÃ³nde empezar",
    "context": {
      "tasks": [
        {"isMandatory": true, "completed": false},
        {"isMandatory": false, "completed": false}
      ],
      "pomodoroSessions": 2,
      "hasPendingTasks": true
    }
  }'
```

Respuesta:
```json
{
  "response": "Cuando te sientas bloqueado, empieza con la tarea MÃS PEQUEÃ‘A...",
  "cached": false,
  "processingTime": 2543
}
```

### Testing con Postman

1. Crear nueva request POST
2. URL: `http://localhost:3000/api/chat`
3. Headers: `Content-Type: application/json`
4. Body (raw JSON):
```json
{
  "message": "Estoy muy distraÃ­do",
  "context": {
    "tasks": [],
    "pomodoroSessions": 0,
    "hasPendingTasks": false
  }
}
```

### EstadÃ­sticas del CachÃ©

```bash
curl http://localhost:3000/api/chat/stats
```

Respuesta:
```json
{
  "cache": {
    "size": 15,
    "hits": 42,
    "misses": 28,
    "evictions": 5,
    "hitRate": "60.00%"
  },
  "uptime": 3600,
  "timestamp": "2025-11-15T12:00:00.000Z"
}
```

---

## ğŸŒ Deployment en Render.com

### Paso 1: Preparar el Repositorio

1. Crear repositorio en GitHub
2. Subir cÃ³digo del backend:

```bash
cd adhd-chatbot-backend
git init
git add .
git commit -m "Initial backend setup"
git remote add origin https://github.com/TU-USUARIO/adhd-chatbot-backend.git
git push -u origin main
```

### Paso 2: Crear Web Service en Render

1. Ir a https://render.com/
2. Registrarse con GitHub (gratis)
3. Dashboard â†’ "New +" â†’ "Web Service"
4. Conectar repositorio `adhd-chatbot-backend`
5. Configurar:

```
Name: adhd-chatbot-api
Environment: Node
Region: Oregon (US West) o el mÃ¡s cercano
Branch: main
Build Command: npm install
Start Command: npm start
Instance Type: Free
```

6. Advanced â†’ Environment Variables:

```
HUGGING_FACE_API_KEY = hf_tu_api_key_aqui
NODE_ENV = production
MAX_REQUESTS_PER_MINUTE = 20
CACHE_TTL_SECONDS = 3600
```

7. Click "Create Web Service"

### Paso 3: Verificar Deployment

Render asignarÃ¡ una URL: `https://tdah-focus.onrender.com`

Verificar health check:

```bash
curl https://tdah-focus.onrender.com/health
```

### Paso 4: Configurar Auto-Deploy

Render detecta automÃ¡ticamente nuevos commits en GitHub y redeploya.

Para deploy manual:
- Dashboard â†’ Tu servicio â†’ "Manual Deploy" â†’ "Deploy latest commit"

### Consideraciones del Tier Gratuito

âš ï¸ **Limitaciones**:
- **Sleep after inactivity**: El servicio se duerme tras 15 min sin requests
- **Wake-up time**: ~30 segundos al recibir el primer request
- **750 horas/mes**: Suficiente para uso 24/7

ğŸ’¡ **SoluciÃ³n para cold starts**:
Implementar ping service (cron job cada 10 min):
- Usar cron-job.org (gratis)
- URL a pingear: `https://tdah-focus.onrender.com/health`
- Frecuencia: Cada 10 minutos

---

## ğŸ“¡ API Reference

### POST /api/chat

Procesa un mensaje del usuario y genera una respuesta usando LLM.

**Request:**

```json
{
  "message": "string (required, max 500 chars)",
  "context": {
    "tasks": [
      {
        "isMandatory": "boolean",
        "completed": "boolean",
        "createdAt": "ISO 8601 string",
        "completedAt": "ISO 8601 string | null"
      }
    ],
    "pomodoroSessions": "number",
    "hasPendingTasks": "boolean"
  }
}
```

**Response (200 OK):**

```json
{
  "response": "string - Generated response",
  "cached": "boolean - True if from cache",
  "processingTime": "number - Milliseconds",
  "fallback": "boolean - True if using pattern-based fallback (optional)"
}
```

**Errors:**

- `400 Bad Request`: Mensaje invÃ¡lido o demasiado largo
- `429 Too Many Requests`: Rate limit excedido (20 req/min)
- `500 Internal Server Error`: Error del servidor

---

### GET /health

Health check del servidor.

**Response (200 OK):**

```json
{
  "status": "ok",
  "timestamp": "ISO 8601 string",
  "uptime": "number - Seconds",
  "environment": "string - development | production"
}
```

---

### GET /api/chat/stats

EstadÃ­sticas del cachÃ© (para monitoreo).

**Response (200 OK):**

```json
{
  "cache": {
    "size": "number",
    "hits": "number",
    "misses": "number",
    "evictions": "number",
    "hitRate": "string - Percentage"
  },
  "uptime": "number - Seconds",
  "timestamp": "ISO 8601 string"
}
```

---

## ğŸ› Troubleshooting

### Error: "Model is loading"

**SÃ­ntoma**: Respuesta "El asistente estÃ¡ iniciando..."

**Causa**: Cold start de Hugging Face (modelo no cargado en memoria)

**SoluciÃ³n**: Esperar 20-30 segundos e intentar de nuevo. El modelo se mantendrÃ¡ cargado por ~15 minutos.

**PrevenciÃ³n**: Usar cron job para ping cada 10 min.

---

### Error: "Authentication failed"

**SÃ­ntoma**: Error 401/403 de Hugging Face API

**Causa**: `HUGGING_FACE_API_KEY` invÃ¡lida o no configurada

**SoluciÃ³n**:
1. Verificar que `.env` tenga el API key correcto
2. Verificar que el token no haya expirado
3. Crear nuevo token en https://huggingface.co/settings/tokens

---

### Error: "Rate limit exceeded"

**SÃ­ntoma**: Error 429

**Causa**:
- LÃ­mite del servidor: >20 requests/minuto desde misma IP
- LÃ­mite de HF: ~1 request/segundo por modelo

**SoluciÃ³n**:
- Esperar 1 minuto
- Implementar debounce en frontend (no enviar mensajes muy rÃ¡pido)
- Aumentar `MAX_REQUESTS_PER_MINUTE` en `.env` (solo si controlas trÃ¡fico)

---

### Respuestas Lentas (>5 segundos)

**Causa**:
- Cold start de modelo
- Cold start de servidor Render
- Prompt muy largo
- TrÃ¡fico alto en HF

**SoluciÃ³n**:
- Implementar ping service para mantener warm
- Usar modelo mÃ¡s pequeÃ±o (`flan-t5-base`)
- Optimizar prompt (reducir contexto)

---

### CORS Error en React Native

**SÃ­ntoma**: "Access to fetch blocked by CORS policy"

**Causa**: Origen no permitido en `ALLOWED_ORIGINS`

**SoluciÃ³n**:
1. En desarrollo local, CORS estÃ¡ deshabilitado
2. En producciÃ³n, agregar origen de Expo a `.env`:
```env
ALLOWED_ORIGINS=http://localhost:19006,exp://192.168.1.100:19000
```

---

## ğŸ“Š Monitoreo y Logs

### Logs del Servidor

Render muestra logs en tiempo real:
- Dashboard â†’ Tu servicio â†’ "Logs"

Buscar:
- `âœ…` Success
- `âŒ` Errors
- `â³` Model loading
- `âš ï¸` Warnings

### MÃ©tricas Importantes

Monitorear:
- **Cache hit rate**: Objetivo >50%
- **Processing time**: Objetivo <3 segundos
- **Error rate**: Objetivo <5%

Ver estadÃ­sticas:
```bash
curl https://tdah-focus.onrender.com/api/chat/stats
```

---

## ğŸ”’ Seguridad

### Mejores PrÃ¡cticas Implementadas

âœ… **Rate limiting**: Previene abuso
âœ… **Input validation**: Valida longitud y tipo de mensaje
âœ… **CORS**: Solo orÃ­genes permitidos
âœ… **No PII**: No se almacena informaciÃ³n personal
âœ… **HTTPS**: ComunicaciÃ³n encriptada (Render provee certificado gratuito)

### Seguridad Adicional para ProducciÃ³n

ğŸ” **Recomendado**:
- Implementar autenticaciÃ³n (API keys por usuario)
- Rate limiting por usuario (no solo IP)
- Logging de requests (sin contenido sensible)
- Alertas de errores (Sentry, Rollbar)

---

## ğŸ“ˆ Escalabilidad

### Capacidad del Tier Gratuito

**EstimaciÃ³n conservadora**:
- 200-300 usuarios/dÃ­a
- 10 mensajes/usuario/dÃ­a
- ~2,000-3,000 mensajes/dÃ­a
- Con cachÃ© 50%: ~1,000-1,500 llamadas a LLM/dÃ­a

**LÃ­mites**:
- HF Free: ~30,000 requests/mes
- Render Free: 750 horas/mes (24/7 ok)

### Plan de Upgrade

Si se excede tier gratuito:

**OpciÃ³n 1: Hugging Face Pro** ($9/mes)
- Inference API sin lÃ­mites
- Sin cold starts
- Modelos privados

**OpciÃ³n 2: Render Starter** ($7/mes)
- 512MB RAM garantizada
- No sleep
- MÃ©tricas avanzadas

**OpciÃ³n 3: Self-hosted** (VPS â‚¬4.50/mes)
- Ejecutar modelo localmente
- Sin lÃ­mites de requests
- MÃ¡s control

---

## ğŸ§ª Testing

### Unit Tests (Opcional)

Estructura para tests:

```javascript
// tests/llmService.test.js
const { generateResponse } = require('../services/llmService');

test('should generate response', async () => {
  const prompt = 'Test prompt';
  const response = await generateResponse(prompt);
  expect(response).toBeDefined();
  expect(response.length).toBeGreaterThan(0);
});
```

Ejecutar:
```bash
npm test
```

### Integration Tests

```bash
# Test completo del flujo
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hola"}'
```

---

## ğŸ“š Recursos

- **Hugging Face Docs**: https://huggingface.co/docs/api-inference/
- **Flan-T5 Model**: https://huggingface.co/google/flan-t5-large
- **Render Docs**: https://render.com/docs
- **Express.js**: https://expressjs.com/

---

## ğŸ¤ ContribuciÃ³n

Este es un proyecto acadÃ©mico (TFG). Para sugerencias:

1. Abrir issue describiendo la mejora
2. Fork del repositorio
3. Crear branch: `git checkout -b feature/mejora`
4. Commit: `git commit -m "Add mejora"`
5. Push: `git push origin feature/mejora`
6. Abrir Pull Request

---

## ğŸ“„ Licencia

MIT License

Copyright (c) 2025 NicolÃ¡s Alejandro Zabala

---

## âœ… Checklist de Deployment

- [ ] Cuenta en Hugging Face creada
- [ ] API key de HF obtenido
- [ ] CÃ³digo testeado localmente
- [ ] Variables de entorno configuradas
- [ ] Repositorio GitHub creado
- [ ] Servicio en Render creado
- [ ] Environment variables en Render configuradas
- [ ] Deployment exitoso
- [ ] Health check verificado
- [ ] Endpoint `/api/chat` testeado
- [ ] URL anotada para frontend
- [ ] (Opcional) Cron job configurado para ping

---

**Ãšltima actualizaciÃ³n**: 15 de noviembre de 2025
**VersiÃ³n**: 1.0.0
**Autor**: NicolÃ¡s Alejandro Zabala
